---
layout: doc
title: Filtering Images
description: Learn how to configure CleanSpeak to filter images automatically using the new media filter
---

[NOTE.since]
====
Available since 3.28.0
====

== Filtering Images
Filtering images is easy with the new media filter

=== Prerequisites
* You have contacted CleanSpeak to have the MediaFilter enabled for your license

=== Considerations
* You will be billed per operation
** An operation on an image is simply the number of enabled filters
** Animated GIFs are billed using `operations` := `number of filters enabled` &times; `number of frames in the GIF`

=== How to configure CleanSpeak to use this feature

==== Setup the image filter
. Navigate to your application configuration
. Enable store content
. Click the media tab
. Enable the image filter (if the image filter is missing then your license does not have the media filter feature enabled and you will need to contact sales)
. Enable at least one filter type [Nudity, Scam, Offensive, Weapon/Alcohol/Drugs]
. Select at least one filter action for the enabled filter (if everything is allow then it will treat the filter as disabled)
. Click save

==== Moderate some content

You can now submit content to this application via the moderate endpoint.

Image moderation works exactly the same as text moderation so you will get a filter response when the filter process is complete.

=== Example usage of the filter

[.endpoint]
.URI
--
[method]#POST# [uri]#/content/item/moderate#
--

For persistent content you will need to provide a unique identifier (UUID) on the API request. When using this API with persistent content you'll need to first ensure your Application configuration is set to Persistent Content Type. If you have not done this the API request will fail with an error message indicating you have not yet configured your Application.
[.endpoint]
.URI
--
[method]#POST# [uri]#/content/item/moderate/`\{contentItemId\}`#
--

[cols="3a,7a"]
[.api]
.Request Parameters
|===
|[field]#contentItemId# [type]#[UUID]# [required]#Required#
|The Id of the Content Item.
|===

[cols="3a,7a"]
[.api]
.Request Body
|===
|[field]#content# [type]#[Object]# [required]#Required#
|The piece of content being moderated.

|[field]#content.applicationId# [type]#[UUID]# [required]#Required#
|The Id of the application that corresponds to the content source.

|[field]#content.createInstant# [type]#[Long]# [required]#Required#
|The link:../reference/data-types#instants[instant] that the content was generated.

|[field]#content.location# [type]#[String]# [optional]#Optional#
|Specifies the location within the application that the content was generated. For example, you might use a chat room
 name, area Id for a game, or a thread Id for a forum. This parameter is used by CleanSpeak to display conversational
 views of content with the <<Context View>> feature.

|[field]#content.parts# [type]#[Array]# [required]#Required#
|An array that contains one to many content parts. If your content only has a single part, such as a chat message, the
 array will only contain a single text entry. The reason you would send in multiple content parts within a single request
 is to ensure the moderation decision affects each part.

For example, you may send in an image for moderation, the image has a title and a description field. You would send this
 to CleanSpeak with three content parts, the image and two text parts. If the content of the image title is rejected the
 entire content needs to be rejected wholesale, the title, description and the image. In this case it would make sense
 to treat all three parts as an atomic unit of content.

If individual content parts are not related and can be rejected or approved separately then you should send them to
 CleanSpeak as separate requests.

|[field]#content.parts``[x]``.content# [type]#[String]# [required]#Required#
|The content to be filtered. This is a publicly reachable url to the content.

|[field]#content.parts``[x]``.name# [type]#[String]# [optional]#Optional#
|The name of the content part. This value is optional an intended to better identify the context when you have more than
 one content part. For example this could be _Title_, _Message Body_ or _Image_.

|[field]#content.parts``[x]``.type# [type]#[String]# [required]#Required#
|The type of this content part. Use `image` for this filter.

Other possible values:

* `text`
* `bbcode`
* `html` [since]#Available Since 3.19.0#
* `attribute`
* `hyperlink`
* `image`
* `video`
* `audio`

|[field]#content.receiverDisplayName# [type]#[String]# [optional]#Optional#
|The display name of the user that received the content. This parameter should only be set if this piece of content was a private message between two users.

|[field]#content.receiverId# [type]#[UUID]# [optional]#Optional#
|The Id of the user that received of the content. This parameter should only be set if this piece of content was a private message between two users.

|[field]#content.senderDisplayName# [type]#[String]# [optional]#Optional#
|The display name (username or whatever is displayed to other users in the game/forum) that generated the content.

|[field]#content.senderId# [type]#[UUID]# [required]#Required#
|The Id of the user that generated the content. This parameter is required so that CleanSpeak can analyze and associate the content with the user that generated it.

|[field]#moderation# [type]#[String]# [optional]#Optional#
|Tells CleanSpeak to forcibly put the content into a queue (Approval, User Alert or Content Alert). This overrides the configuration you have setup for the Application in the Management Interface.

* `requiresApproval`
* `generatesAlert`
* `generatesContentAlert`
|===

[source,json]
.Example Request JSON
----
{
  "content": {
    "applicationId": "f81d4fae-7dec-11d0-a765-00a0c91e6bf6",
    "createInstant": 13405983821,
    "location": "page296",
    "parts": [
      {
        "content": "https://s3.us-east-2.amazonaws.com/public-resources-us-east.inversoft.com/image-moderation/sfw/not-porn.jpg",
        "name": "Body",
        "type": "image"
      }
    ],
    "senderDisplayName": "PapaSmurf",
    "senderId": "f6d3df91-ed4b-48ad-810f-05a367d328c2"
  }
}
----

=== Response

include::docs/3.x/tech/apis/_standard-post-response-codes.adoc[]

[cols="3a,7a"]
[.api]
.Response Body
|===
|[field]#content# [type]#[Object]#
|The piece of content being moderated.

|[field]#content.id# [type]#[UUID]#
|The id of the piece of content. This might have been passed in on the request or generated by CleanSpeak.

|[field]#content.parts# [type]#[Array]#
|The list of parts of content.

|[field]#content.parts[x].mediaFilterResult.alcoholConfidence# [type]#[Float]#
|The confidence that the image contains alcohol imagery.

|[field]#content.parts[x].mediaFilterResult.drugsConfidence# [type]#[Float]#
|The confidence that the image contains drug imagery.

|[field]#content.parts[x].mediaFilterResult.offensiveResults[x].offensiveConfidence# [type]#[Float]#
|The confidence that the image contains offensive content.

|[field]#content.parts[x].mediaFilterResult.offensiveResults[x].offensiveTag# [type]#[String]#
|The tag for the type of offensive content.

|[field]#content.parts[x].mediaFilterResult.offensiveResults[x].position# [type]#[Float]#
|The frame that the offensive content exists on.

|[field]#content.parts[x].mediaFilterResult.partialNudityConfidence# [type]#[Float]#
|The confidence that the image contains partial nudity.

|[field]#content.parts[x].mediaFilterResult.partialNudityTag# [type]#[String]#
|The associated tag for the type of partial nudity.

|[field]#content.parts[x].mediaFilterResult.rawNudityConfidence# [type]#[Float]#
|The confidence that the image contains raw nudity.

|[field]#content.parts[x].mediaFilterResult.scamConfidence# [type]#[Float]#
|The confidence that the image is a known scammer image.

|[field]#content.parts[x].mediaFilterResult.weaponConfidence# [type]#[Float]#
|The confidence that the image contains weapon.

|[field]#content.parts[x].name# [type]#[String]#
|The name of the part of the content.

|[field]#content.parts[x].replacement# [type]#[String]#
|The replacement text generated by CleanSpeak after applying the filter rules to this part.

|[field]#contentAction# [type]#[String]#
|The action that the client should take with the content. Possible values:

_Content Actions_
!===
!Action              !Description

!`allow`             !The content should be allowed.
!`authorOnly`        !The content should be allowed but only the author of the content should be allowed to view the content.
!`replace`           !The content should be allowed, but utilize the replacement text provided in the response.
!`queuedForApproval` !The content has been queued for approval and should not be displayed to other users until it has been approved by a moderator.
!`reject`            !The content should be rejected.
!===

|[field]#moderationAction# [type]#[String]#
|The action that was taken on the content. Possible values:

* `requiresApproval`
* `generatesAlert`
* `generatesContentAlert`

|[field]#stored# [type]#[Boolean]#
|This value indicates if the content was stored by CleanSpeak.
|===

[source,json]
.Example Response JSON
----
{
  "content": {
    "id": "99f2c4e8-961a-4a34-b9b9-43fc3f3b43ec"
  },
  "contentAction": "allow",
  "stored": true
}
----
